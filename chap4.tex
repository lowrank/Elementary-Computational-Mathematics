\chapter{Approximation}
\label{Ch: 4-App}
The approximation solves the problem 
$$\min_{p\in P}\|f - p\|_{\cX}$$
which aims to select the function $p\in P$ in a specific set with the minimum distance under a certain metric $\|\cdot\|_{\cX}$ from the target function $f$. 
\section{General Approximation Theory}
\label{Sec: 4-Gen-App-The}
The most famous example in approximation theory is the least square problem 
$$\min_{x\in S} \|Ax - b\|_2$$
where $A\in\bbR^{N\times k}$ and a given vector $b\in \bbR^N$. Seeking for solution $x\in S = \bbR^k$ is the simplest case. The problem can be efficiently solved if $S$ is a convex set. 
\begin{definition}
    Let $\cM\subset \cV$ of a normed space $(\cV, \|\cdot\|)$ and given $v\in\cV$, the best approximation in $\|\cdot\|$ is 
    $$u^{\ast}\in\cM,\quad \|u^{\ast} - v\| = \inf_{u\in\cM} \|u - v\|$$
\end{definition}
\begin{definition}
    The sequence $u_k$, $k\in\bbN$ is an minimizing sequence if 
    \begin{equation}
        u_k \in\cM,\quad \|u_k - v\|\to \inf_{u\in\cM}\|u - v\|,\quad k\to\infty.
    \end{equation}
\end{definition}
\begin{theorem}[existence of best approximation]
\label{Thm: 4-Exi-Bes-App}
If $u_k$ is a minimizing sequence and has an accumulation point $u^{\ast}$ in $\cM$, then  $u^{\ast}$ is a best approximation to $v$.
\end{theorem}
\begin{proof}
    Just take the limit (subsequence) on both sides to 
    \begin{equation}
        \|u^{\ast} - v\| \le \|u^{\ast} - u_k\| + \|u_k - v\|.
    \end{equation}
\end{proof}
\begin{theorem}
\label{Thm: 4-Com-Exi}
    If $\cM$ is a compact subset of $\cV$, then the best approximation always exists.
\end{theorem}
\begin{proof}
    
\end{proof}
One special case is that $\cM$ is a finite dimension linear subspace of $\cV$, then one can take a bounded closed set truncating the minimizing sequence, then such set must be compact.
\begin{lemma}[convexity]
\label{Lem: 4-CON}
If $\cM$ is a convex set of normed space $\cV$, then the set of best approximations is convex.
\end{lemma}
\begin{proof}
    
\end{proof}
\begin{theorem}[uniqueness]
\label{Thm: 4-Uni-1}
    If $\cM$ is strictly convex of normed space $\cV$, then the best approximation is unique. It is worthwhile to notice that strictly convexity is sufficient but not necessary.
\end{theorem}
\begin{proof}
    
\end{proof}
\begin{definition}
   The normed space $(\cV, \|\cdot\|)$ is strictly normed if and only if the unit ball is strictly convex).
\end{definition}
\begin{theorem}[uniqueness]
\label{Thm: 4-Uni-2}
    If $\cM$ is a strictly normed linear subspace of normed space $\cV$, then there exists at most one best approximation for each $v\in\cV$.
\end{theorem}
\begin{proof}
    
\end{proof}

\begin{remark}
    The above theorems are quite preliminary in general Banach spaces. Formalizing the proofs with $\texttt{Lean}$ is recommended. See Exercises.  
\end{remark}

\section{Minimax Approximation}
\label{Sec: 4-MIN-APP}
Given $f\in C^0([a, b])$, find a polynomial $p_n\in\Pi_n$ such that $$\|f - p_n\|_{\infty} = \min_{g\in\Pi_n} \|f - g\|_{\infty}$$
Such a problem is a typical minimax approximation problem. In the previous Chapter~\ref{Ch: 2-Int}, we have seen a similar problem which is to minimize the maximum of $|\omega(x)|$ with $\omega(x) = \prod_{j=0}^n(x - x_j)$. The proof used there can be borrowed for the following theorem as well. 

\begin{theorem}[de la Vall\'ee-Poussin]
\label{Thm: 4-DE-LA-VAL-POU}
    Let $f\in C^0([a, b])$ and $n\ge 0$, let $x_0<x_1<\dots<x_{n+1}$ be $n+2$ nodes in $[a, b]$. If there exists a polynomial $q_n\in\Pi_n$ such that 
    $$f(x_j) - q_n(x_j) = (-1)^j e_j,\quad j =0,\dots, n+1.$$ 
    where $e_j$ are having the same sign and nonzero, then 
    \begin{equation}
        \min_j |e_j|\le E_n^{\ast}(f): = \min_{g\in\Pi_n} \|f - g\|_{\infty} \le \max_j |e_j|.
    \end{equation}
\end{theorem}

\begin{proof}
    Prove by contradiction. Suppose $E_n^{\ast}(f)$ is achieved by some polynomial $g\in\Pi_n$. If $q_n$ satisfies that 
    \begin{equation}
        |e_j| > E_n^{\ast}(f) = \|f - g\|_{\infty} \quad \forall j=0,1,\cdots n+1.
    \end{equation}
    Then, $q_n - g = q_n - f - (g - f)$ implies that 
    \begin{equation}
    \sgn(q_n - g)(x_j) = \sgn(q_n - f)(x_j) = -(-1)^j\sgn(e_j),
    \end{equation}
    which changes sign $n+1$ times while $q_n - g$ only has $n$ roots.
\end{proof}
The above theorem implies the sufficiency of the ``equioscillation'' property of length $n+2$ for the minimax approximation. The next theorem shows it is also necessary.
\begin{theorem}[Chebyshev equioscillation theorem]
\label{Thm: 4-Che-Equ}
    Let $f\in C^0([a, b])$ and $n\ge 0$. Then there exists a \emph{unique} polynomial $q^{\ast}\in\Pi_n$ such that 
    \begin{equation}
        E_{n}^{\ast}(f) = \|f - q_n^{\ast}\|_{\infty}.
    \end{equation}
    This polynomial is uniquely characterized by the property that 
    $\exists a\le x_0<\dots < x_{n+1}\le b$ 
    for which we can select $\sigma = \pm 1$ that 
    \begin{equation}\label{EQ: 4-EQUI-OSCI}
        f(x_j) - q_n^{\ast}(x_j) = \sigma (-1)^j \|f - q_n^{\ast}\|_{\infty} ,\quad j=0,1,\dots, n+1.
    \end{equation}
\end{theorem}
\begin{proof}
    The existence of such minimizing polynomial $q^{\ast}\in\Pi_n$ can be proved through a minimizing sequence argument. Let $q^k\in \Pi_n$ be a minimizing sequence to having $\|q^k - f\|\to E_n^{\ast}(f)$, then it is clear that the set 
    \begin{equation}
        \cM = \{q\in \Pi_n\mid \|q - f\|\le  E_n^{\ast}(f) + 1\}
    \end{equation}
    must be non-empty and such a set is compact since $\cM$ is of finite dimension and closed. Then the minimizing sequence will have a converging sub-sequence, so the limit sits in $\cM$.

    Then we show it is necessary (sufficiency by Theorem~\ref{Thm: 4-DE-LA-VAL-POU}) to have~\eqref{EQ: 4-EQUI-OSCI} for this minimizing polynomial $q_n$. If it is not satisfied, then we can partition the interval $[a, b]$ into $1\le N\le n+1$ parts 
    $$[a, b]=\cup_{j=1}^N [t_{j-1}, t_j],\quad a = t_0<\dots< t_N = b,$$
    such that 
    \begin{enumerate}
        \item $f(t_k) - q_n(t_k) = 0$, $k = 1,\dots, N-1$.
        \item for each $1\le k\le N$, there exists (may not be unique) $s_k\in [t_{k-1}, t_k]$ such that 
        $$|f(s_k) - q_n(s_k)| = \|f - q_n\|_{\infty}\neq 0$$
        and for any $x\in [t_{k-1}, t_k]$, 
        $$-(f(x) - q_n(x)) \neq (f(s_k) - q_n(s_k)).$$
        \item for each $1\le k\le N-1$, 
        $$f(s_k) - q_n(s_k) = -(f(s_{k+1}) - q_n(s_{k+1}) ).$$
    \end{enumerate}
    Without loss of generality, one can assume that 
    \begin{eqnarray}
        \sgn(f(s_k) - q_n(s_k)) = (-1)^{k-1}, 
    \end{eqnarray}
    then using the second condition, there exists $\eps$ such that $\forall x\in [t_{k-1}, t_k]$,
    \begin{equation}
        \begin{aligned}
            -\|f-q_n\|_{\infty} + \eps &\le  f(x) - q_n(x)\quad& k &\text{ is odd}\\
            f(x) - q_n(x) &\le \|f-q_n\|_{\infty} - \eps\quad& k &\text{ is even}     
        \end{aligned}
    \end{equation}
    Then we construct a polynomial $g\in \Pi_{N-1}$ that 
    \begin{eqnarray}
        \sgn(g(x)) = (-1)^k,\quad x\in[t_{k-1}, t_k].
    \end{eqnarray}
    and $\|g\|\le \frac{\eps}{2}$ and let $k(x) = q_n(x) - g(x)\in \Pi_{n}$ and $f(x) - k(x) = f(x)-q_n(x) + g(x)$, which implies that 
    \begin{enumerate}
        \item $f(x) - k(x) < f(x) - q_n(x)$, if $x\in (t_{k-1}, t_k)$ for $k$ odd.
        \item $f(x) - k(x)\ge - \|f - q_n\| + \frac{\eps}{2}$, if $x\in (t_{k-1}, t_k)$ for $k$ odd.
        \item $f(x) - k(x) > f(x) - q_n(x)$, if $x\in (t_{k-1}, t_k)$ for $k$ even.
        \item $f(x) - k(x)\le \|f - q_n\| -\frac{\eps}{2}$, if $x\in (t_{k-1}, t_k)$ for $k$ odd.
    \end{enumerate}
    In this way, $\|f - k\|_{\infty} < \|f - q_n\|_{\infty}$, which is a contradiction.

    In the last, we show the uniqueness. Suppose there are two polynomials $q_n, \tilde{q}_n$ being the minimax approximation. Then $\frac{1}{2}(q_n +\tilde{q}_n)$ must also be a minimax approximation, therefore there exist the alternation nodes 
    \begin{equation}
        a\le s_0 < s_1 <\dots < s_{n+1} \le b
    \end{equation}
    such that 
    \begin{equation}
        \frac{1}{2}(q_n - f)(s_k) + \frac{1}{2}(\tilde{q}_n - f)(s_k) = \sigma (-1)^k E_n^{\ast}(f)
    \end{equation}
    Therefore, we must have 
    \begin{equation}
        (q_n - f)(s_k) = (\tilde{q}_n - f)(s_k)\Rightarrow q_n(s_k) = \tilde{q}_n(s_k),
    \end{equation}
    which implies $q_n = \tilde{q}_n$ by the uniqueness of interpolation. 
\end{proof}

\begin{remark}
    If the approximation is under $L^{2}$ norm instead of $C^0$ norm, then  
    \begin{equation}
        f_n^{\ast} = \argmin_{f_n \in \Pi_n }\|f - f_n\|_{L^2[a, b]} = \sum_{k=0}^{n} a_k p_k
    \end{equation}
    where $\{p_k\}_{k\ge 0}$ is the set of orthogonal polynomials (Legendre polynomials) on $[a, b]$ and the coefficients $a_k = \aver{f, p_k}/\aver{p_k, p_k}$. 
\end{remark}

\subsection{Remez Algorithm}
The Chebyshev equioscillation theorem does not provide a constructive way to find the best polynomial approximation in $L^{\infty}$ norm. However, the numerical method to find the minimax polynomial could adopt the idea of the above Chebyshev equioscillation theorem. Intuitively, the aiming polynomial will be oscillatory compared with $f$, therefore we can start with the Chebyshev polynomial approximation, which is
\begin{equation}
    C_n(x) = \sum_{j=0}^n c_j T_j(x),\quad c_j = \aver{f, T_j}_w/\aver{T_j,T_j}_w
\end{equation}
where $w = (1-x^2)^{-1/2}$. The convergence is uniform as $n\to \infty$, especially if $f\in C^r([a, b])$, the coefficient $c_j\sim \cO(j^{-r})$ decays fast, then the reminder approximately $f - C_n\simeq c_{n+1}T_{n+1}$, this reminder achieves equioscillation at exactly $(n+2)$ points. The Remez algorithm (see Algorithm~\ref{ALG: REMEZ}) is based on the above idea and performs an iterative construction.
\begin{algorithm}[!htbp]
    \SetAlgoLined
    \caption{Remez algorithm for polynomial approximation on $[-1,1]$}    \label{ALG: REMEZ}
    \KwData{Objective function $f(x)$ on $[-1, 1]\subset \mathbb{R}$}
    \KwResult{Polynomial $p(x)\in\Pi_n$ and estimated error $E$}
    $\{x_j\}_{j=0}^n\gets \texttt{findExtreme}(T_{n+1})$//  Initialize local extrema nodes of $T_{n+1}$; 
    \\
    \While{True}{
        Solve the equation for $a_j$ and $E$,
        \begin{equation}
            \sum_{j=0}^{n} a_j x_k^j + (-1)^k E = f(x_k),\quad k = 0, \cdots n+1;
        \end{equation}\\
        $p(x) \gets \sum_{j=0}^{n} a_j x^j$; // new candidate polynomial; \\ 
        $\text{stop} \gets \texttt{isEquioscillation}(p - f)$ // check equioscillation condition~\eqref{EQ: 4-EQUI-OSCI} ; \\
        \eIf {stop}{ 
            return \\
        }
        {
            $\{x_j\}_{j=0}^n\gets \texttt{findExtreme}((p - f))$ // find local extrema nodes of $p - f$.
        }
    }
\end{algorithm}
\subsection{Polynomial Approximation for Analytic Functions}
Let $f(z)$ be an analytic function inside a domain
$D_{\rho}\subset \bbC$, where a finite interval $I\subset D_{\rho}$. Usually, $f$ can be well approximated by polynomials in $D_{\rho}$. Here, the parameter $\rho$ and the definition of $D_{\rho}$ will be elaborated later. In particular,   
\begin{equation}
    E_{n,\infty}(f) = \min_{f_n\in \Pi_n} \|f - f_n\|_{L^{\infty}(I)}
\end{equation}
decays very quickly in terms of $n$. Let $p_n\in \Pi_n$, $n = 0,1,\cdots$ be the orthogonal polynomials over $I\subset \bbR$ with the analytic weight $w$.  Suppose one can represent (pointwise convergence)
\begin{equation}
    f(x) = \sum_{n=0}^{\infty} a_n p_n(x), \quad a_n = \frac{\aver{f, p_n}_w}{\aver{p_n, p_n}_w}, 
\end{equation}
then, $E_{n, \infty}(f) \le  \sum_{k > n} | a_k | \sup_{I} \left| p_k \right|$. Therefore, we only have to estimate the coefficients $|a_n|$. 
\begin{definition}[weighted Cauchy transform]
\label{Def: 4-Wei-Cau-Tra}
Let $x\in \bbR$ and suppose $w(x) p_n(x)$ satisfies that 
\begin{equation}
    |w(x) p_n(x)| \le C_n \max_{1\le j\le J} \frac{1}{|x - t_j|^{\alpha}}, \quad \alpha \in (0, 1)
\end{equation}
for a finite number of $t_j\in \bbR$. Then the weighted Cauchy transform of $p_n$ is defined by 
\begin{equation}
    P_n(z) = \frac{1}{2\pi i} \int_{I} \frac{w(x) p_n(x)}{z - x} dx,\quad z \in \bbC - \overline{I}. 
\end{equation}
\end{definition}
Clearly, $P_n(z)$ is a holomorphic function in $\bbC - \overline{I}$. In addition, if $|z|\to \infty$, then $|P_n(z)| = \cO(|z|^{-1})$. 
\begin{lemma}[Plemelj formula]
\label{Lem: 4-PLE-For}
    For any $x\in I$, then 
    $$\lim_{\eps\to 0^{+}}P_n(x - \eps i) - P_n(x + \eps i) = w(x) p_n(x). $$ 
\end{lemma}
\begin{proof}
    Let $\delta_{\eps}(x) =  \frac{1}{\pi} \frac{\eps}{x^2 + \eps^2}$ and notice that 
    \begin{equation}
    \begin{aligned}
           P_n(x - \eps i) - P_n(x + \eps i) &= \frac{1}{2\pi i } \int_I w(y)p_n(y) \left(\frac{1}{x - \eps i - y}  - \frac{1}{x + \eps i - y} \right) \\ 
           &= \int_I \delta_{\eps}(x-y) \ast  w(y) p_n(y)  dy \\
           &\to  w(x) p_n(x).
    \end{aligned}
    \end{equation}
\end{proof}
\begin{lemma}
\label{Lem: 4-Coe-Pol}
    If $f$ is analytic and bounded in the domain $D_{\rho}$ and the weight $w$ satisfies the condition in Definition~\ref{Def: 4-Wei-Cau-Tra}, 
    then the projection can be computed by the contour integral
    \begin{equation}
        \aver{f, p_n}_w = \int_{\cC_{\rho}} f(z) P_n(z) dz,
    \end{equation}
    where the contour $\cC_{\rho} = \partial D_{\rho}$.
\end{lemma}
\begin{proof}
    Since the functions $f(z)$ and $p_n(z) w(z)$ are analytic in $D_{\rho}$ except a finite number of points. Due to the mild growth of $w(x)p_n(x)$, the infinitesimal contours around these points will not contribute. Therefore, the contour $\cC_{\rho}$ can be deformed in lower and upper half-planes to the $x$-axis. Then, use Lemma~\ref{Lem: 4-PLE-For}, 
    \begin{equation}
         \int_{\cC} f(z) P_n(z) dz = \lim_{\eps\to 0} \int_{I}  P_n(x - \eps i) + P_n(x + \eps i) f(x) dx = \int_{I} f(x) p_n(x) w(x) dx. 
    \end{equation}
    The Lemma~\ref{Lem: 4-Coe-Pol} implies a trivial bound by the maximal modulus principle.
\end{proof}
The following examples estimate the approximation error for Chebyshev polynomials and Legendre polynomials. The Cauchy transforms are from~\cite{elliott1974asymptotic}.
\begin{example}
    For Chebyshev polynomials on $I = [-1,1]$ that $w(x) = (1 - x^2)^{-1/2}$, then $|p_n|$ are bounded by one,  
    \begin{equation}
        P_n(z) = \frac{1}{2i (z^2 - 1)^{1/2} [z + (z^2 - 1)^{1/2}]^n},\quad z \notin [-1, 1].
    \end{equation}
    Therefore, if we choose $D_{\rho} = \{|z + (z^2 - 1)^{1/2}| \le \rho\}$ for $\rho > 1$, the domain is an ellipse with foci at $\pm 1$, the ellipse is also called the Berstein ellipse. Then use $\aver{p_n, p_n} = \frac{\pi}{2}$ for $n > 1$, 
    \begin{equation}
        |a_n| \le \frac{\sup_{\cC_{\rho}} |f|}{\pi \rho^n } \int_{\cC_{\rho}} \frac{1}{|(z^2 - 1)|^{1/2}} d|z| = \frac{2}{\rho^n} \sup_{\cC_{\rho}} |f|.
    \end{equation}
    This implies the approximation error $E_{n,\infty}(f) \le \sum_{k > n} \frac{2}{\rho^k} \sup_{\cC_{\rho}} |f| = \cO(\rho^{-n})$.
\end{example}
\begin{example}
    For Legendre polynomials on $I = [-1, 1]$ that $w(x) = 1$ and $\aver{p_n, p_n} = \frac{2}{2n+1}$, the polynomials $|p_n|$ are bounded by one, then 
    \begin{equation}
        P_n(z) = \frac{2^{2n+1/2}|\Gamma(n+1)|^2}{i\pi \Gamma(2n+2)(z+(z^2-1)^{1/2})^{n+1/2}} (z^2-1)^{-1/4},\quad z\notin [-1,1].
    \end{equation}
    Then in the Berstein ellipse $D_{\rho}$, 
    \begin{equation}
        |a_n|\le \frac{\sup_{\cC_{\rho}}|f|}{\pi \rho^{n + 1/2} } \frac{2^{2n-1/2}(n!)^2 }{ (2n)!  }\int_{\cC_{\rho}} \left|(z^2 - 1)^{-1/4}\right| d|z| = \cO\left(\frac{\sqrt{ n}\sup_{\cC_{\rho}|f|}}{\rho^n}\right).
    \end{equation}
    Therefore, if $n > |\log \rho|^{-1}$ is sufficiently large, the approximation error
    \begin{equation}
    \begin{aligned}
        E_{n,\infty}(f) &= \cO\left(\sup_{\cC_{\rho} } |f| \sum_{k>n}\frac{\sqrt{k}}{\rho^k}\right) = \cO(\sqrt{n}\rho^{-n}).
    \end{aligned}
    \end{equation}
\end{example}
\begin{remark}
    It can be shown for the general Jacobi polynomials $p_n$ with weight $(1-x)^{\alpha}(1+x)^{\beta}$, the coefficient 
    $|a_n| = \cO(\sqrt{n} \rho^{-n} )$ as the previous example. However, let $q = \max(\alpha, \beta)$, then 
    \begin{equation}
        E_{n,\infty}(f) = \sum_{k>n} \cO\left(\sqrt{k} \rho^{-k} \sup_{[-1,1]} |p_k|\right) = \begin{cases}
            \cO\left( n^{q+\frac{1}{2}}\rho^{-n}\right),\quad & q\ge -\frac{1}{2},        \\
             \cO\left( \rho^{-n} \right),\quad & q < -\frac{1}{2}. 
            \end{cases}
    \end{equation}
    In other words, the Chebyshev polynomials have attained the best bound. The approximation error by Legendre polynomials only differs by a factor of $\sqrt{n}$. 
\end{remark}
\section{Approximation Theory on Compact Groups}
\subsection{\mathtitle{$\mathrm{SO(n)}$}}

\section{Pad\'e Approximation}
Instead of linearly combining the basis functions for approximation, it is also possible to introduce nonlinear dependencies of the parameters for approximation. The most common one is the rational approximation. It uses the rational functions 
\begin{equation}
    R(x) = \frac{a_0 + a_1 x + \cdots + a_n x^n}{b_0 + b_1 x + \cdots + b_m x^m}
\end{equation}
to approximate the objective functions.
\section{Rank one approximation}
\section{Neural Network}
\subsection{Radial Basis}
\subsection{Universal Approximation Theorem}
\subsection{Gradient-Flow}
\section{Exercises}
\subsection{Theoretical Part}
\begin{problem}
    Show that the vector space $C^0([a, b])$ with $\|\cdot\|_{\infty}$ is not strictly normed.
\end{problem}
\begin{problem}
    Let $f(x)\in C^0([-1,1])$ is even (odd). Show that the minimax approximation $q_n(x)\in\Pi_n$ is also even (odd).
    Hint: think about the function $\frac{1}{2}(q_n(x) \pm q_n(-x))$, then use the Chebyshev equioscillation theorem and the uniqueness.
\end{problem}

\subsection{Computational Part}
\begin{problem}
    Implement the Remez algorithm and find the minimax approximation in $\Pi_3$ for the function $f(x) = e^x$ on $[0, 1]$.
\end{problem}

\begin{problem}
    Formalize the theorem/proofs in Section~\ref{Sec: 4-Gen-App-The} with \texttt{Lean}.
\end{problem}

\nocite{trefethen2019approximation,cheney2009course, muskhelishvili2008singular, elliott1974asymptotic}
\bibliographystyle{apalike}
\bibliography{chap4}
